{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consultas de datos metereologicos para estaciones relacionadas con Barcelona. Datos 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">#### Utilizaremos una copia de la siguiente libreria (https://github.com/pablo-moreno/python-aemet) ya creada y paquetizada con todos los metodos para hacer las consultas a la Api. \n",
    ">#### De las librerias python para consultas a aemet disponibles, esta parece ser que esta bastante bien documentada y mantenida.\n",
    ">#### La instalamos y hacemos un help a ver como trabajar con esta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#pip install python-aemet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aemet\n",
    "help(aemet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**-Nos interesa estudiar el archivo models.py para ver como trabaja la libreria**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definimos nuestra api key previamente solicitada en la web de aemet opendata:https://opendata.aemet.es/centrodedescargas/inicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mi_API_KEY='eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJqYXVtZUBncmVlbmZvb2RpYmVyaWNhLmVzIiwianRpIjoiMWFmMmM5ZDMtMDBhZS00YWMwLTk2ZjctZTYzODZiYzQ3NDRjIiwiaXNzIjoiQUVNRVQiLCJpYXQiOjE2MDIwMDcyNjEsInVzZXJJZCI6IjFhZjJjOWQzLTAwYWUtNGFjMC05NmY3LWU2Mzg2YmM0NzQ0YyIsInJvbGUiOiIifQ.R9v0ZXsF3sN-_p87RjELY91YYTVWqx_DqellRX9xCD4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En el portal de aemet podemos testear y consultar que tipos de datos nos interesan (https://opendata.aemet.es/centrodedescargas/productosAEMET?) y con mas detalle de como trabajar la consulta con la API (https://opendata.aemet.es/dist/index.html?)\n",
    "\n",
    ">#### En nuestro caso nos podra interesar:\n",
    ">#### 1* Los valores climatologicos diarios de las mismas estaciones objetivo para hacer la consulta de los historicos. valores estacion vs date\n",
    ">#### \n",
    ">#### 2 Los datos de las ultimas observaciones convencionales por estaciones objetivo. Ofrecen datos por hora. valores por estacion vs date time\n",
    ">#### (es posible montar una estructura de consultas realtime para trabajar las predicciones de nuestro modelo ?) (hay que tener en cuenta limite peticiones por minuto/key)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### En qualquier caso primero consultamos las estaciones disponibles para definir las estaciones objetivo. Lo metemos en un df de pandas para posteriormente filtrar por provincia y estacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aemet import Aemet, Estacion\n",
    "import json\n",
    "\n",
    "\n",
    "aemet = Aemet(api_key=Mi_API_KEY)\n",
    "estaciones = Estacion.get_estaciones(api_key=Mi_API_KEY)[:]\n",
    "#print(estaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df_estaciones = pd.DataFrame(estaciones)\n",
    "df_estaciones.columns=['latitud','provincia','altitud','indicativo','nombre','indsinop','longitud']\n",
    "df_estaciones.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mad_bcn_estaciones = df_estaciones[df_estaciones[\"provincia\"].isin(['BARCELONA', 'MADRID'])]\n",
    "\n",
    "print(mad_bcn_estaciones)\n",
    "\n",
    "mad_bcn_estaciones.to_csv('para qlik/mad_bcn_estaciones.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De momento para barcelona utilizamos:\n",
    "#### 1 0076 BARCELONA BARCELONA AEROPUERTO\n",
    "#### 2 0200E BARCELONA BARCELONA, FABRA \n",
    "#### (Una vez pre analizados los datos de presión descartamos la estación BCN FABRA de la agrupación al tener una altitud muy diferente a las otras 2 estaciones. La estación está ubicada en el monte del Tibidabo mientras que las otras 2 estaciones están cerca del nivel del mar que es donde se concentra la mayoría de la ciudad)\n",
    "#### 3 0201D BARCELONA BARCELONA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consulta a la api para 1 0076 BARCELONA BARCELONA AEROPUERTO \n",
    "import datetime as dt\n",
    "\n",
    "aemet = Aemet(Mi_API_KEY)\n",
    "estaciones = Estacion.get_estaciones(Mi_API_KEY)[1:2]\n",
    "#estaciones = Estacion.get_estaciones(Mi_API_KEY)[0:7]\n",
    "datos = []\n",
    "#todavia no atino con el formato de fecha adecuado pero lo meto en en stg como lo quiere aemet y ya hace la llamada correcta para conseguir los vcm de la estacion objetivo\n",
    "fechaini=dt.datetime.strptime(\"2020-1-1\",'%Y-%m-%d',)\n",
    "fechafin=dt.datetime.strptime(\"2020-12-31\",'%Y-%m-%d')\n",
    "\n",
    "\n",
    "for estacion in estaciones:\n",
    "    print('{}: {}'.format(estacion['indicativo'], estacion['nombre']))\n",
    "    \n",
    "    vcm = aemet.get_valores_climatologicos_diarios('2020-01-01T00:00:00UTC','2020-12-31T00:00:00UTC', estacion['indicativo'])\n",
    "    resultado = {\n",
    "        'estacion': estacion,\n",
    "        'valores_climatologicos': vcm,\n",
    "    }\n",
    "    datos.append(resultado)\n",
    "\n",
    "#print(json.dumps(datos, indent=2))\n",
    "print(fechaini)\n",
    "print(fechafin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados en un dataframe\n",
    "import pandas as pd \n",
    " \n",
    "df_estacion_datos_diarios1 = pd.DataFrame(vcm)\n",
    "df_estacion_datos_diarios1.columns=['fecha','indicativo','nombre','provincia','altitud','tmed','prec','tmin','horatmin','tmax','horatmax','dir','velmedia','racha','horaracha','sol','presmax','horapresmax','presmin','horapresmin']\n",
    "df_estacion_datos_diarios1.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A continuacion dejo el codigo para fabra como mención:\n",
    "#Consulta a la api para 2 0200E BARCELONA BARCELONA, FABRA \n",
    "#import datetime as dt\n",
    "\n",
    "#aemet = Aemet(Mi_API_KEY)\n",
    "#estaciones = Estacion.get_estaciones(Mi_API_KEY)[2:3]\n",
    "##estaciones = Estacion.get_estaciones(Mi_API_KEY)[0:7]\n",
    "#datos = []\n",
    "#todavia no atino con el formato de fecha adecuado pero lo meto en en stg como lo quiere aemet y ya hace la llamada correcta para conseguir los vcm de la estacion objetivo\n",
    "#fechaini=dt.datetime.strptime(\"2018-1-1\",'%Y-%m-%d',)\n",
    "#fechafin=dt.datetime.strptime(\"2019-12-31\",'%Y-%m-%d')\n",
    "\n",
    "\n",
    "#for estacion in estaciones:\n",
    "#    print('{}: {}'.format(estacion['indicativo'], estacion['nombre']))\n",
    "    \n",
    "#    vcm2 = aemet.get_valores_climatologicos_diarios('2018-01-01T00:00:00UTC','2019-12-31T00:00:00UTC', estacion['indicativo'])\n",
    "#    resultado = {\n",
    "#        'estacion': estacion,\n",
    "#        'valores_climatologicos': vcm,\n",
    "#    }\n",
    "#    datos.append(resultado)\n",
    "\n",
    "#print(json.dumps(datos, indent=2))\n",
    "#print(fechaini)\n",
    "#print(fechafin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados en un dataframe\n",
    "#import pandas as pd \n",
    " \n",
    "#df_estacion_datos_diarios2 = pd.DataFrame(vcm2)\n",
    "#df_estacion_datos_diarios2.columns=['fecha','indicativo','nombre','provincia','altitud','tmed','prec','tmin','horatmin','tmax','horatmax','dir','velmedia','racha','horaracha','sol','presmax','horapresmax','presmin','horapresmin']\n",
    "#df_estacion_datos_diarios2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consulta a la api para 3 0201D BARCELONA BARCELONA \n",
    "import datetime as dt\n",
    "\n",
    "aemet = Aemet(Mi_API_KEY)\n",
    "estaciones = Estacion.get_estaciones(Mi_API_KEY)[3:4]\n",
    "#estaciones = Estacion.get_estaciones(Mi_API_KEY)[0:7]\n",
    "datos = []\n",
    "#todavia no atino con el formato de fecha adecuado pero lo meto en en stg como lo quiere aemet y ya hace la llamada correcta para conseguir los vcm de la estacion objetivo\n",
    "fechaini=dt.datetime.strptime(\"2020-1-1\",'%Y-%m-%d',)\n",
    "fechafin=dt.datetime.strptime(\"2020-12-31\",'%Y-%m-%d')\n",
    "\n",
    "\n",
    "for estacion in estaciones:\n",
    "    print('{}: {}'.format(estacion['indicativo'], estacion['nombre']))\n",
    "    \n",
    "    vcm3 = aemet.get_valores_climatologicos_diarios('2020-01-01T00:00:00UTC','2020-12-31T00:00:00UTC', estacion['indicativo'])\n",
    "    resultado = {\n",
    "        'estacion': estacion,\n",
    "        'valores_climatologicos': vcm,\n",
    "    }\n",
    "    datos.append(resultado)\n",
    "\n",
    "#print(json.dumps(datos, indent=2))\n",
    "print(fechaini)\n",
    "print(fechafin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resultados en un dataframe\n",
    "import pandas as pd \n",
    " \n",
    "df_estacion_datos_diarios3 = pd.DataFrame(vcm3)\n",
    "df_estacion_datos_diarios3.columns=['fecha','indicativo','nombre','provincia','altitud','tmed','prec','tmin','horatmin','tmax','horatmax','dir','velmedia','racha','horaracha']\n",
    "df_estacion_datos_diarios3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenamos los 2 dataframes en 1 solo aunque no tengan el mismo nuemro de columnas\n",
    "#df_estacion_datos_diarios=pd.concat([df_estacion_datos_diarios1,df_estacion_datos_diarios2,df_estacion_datos_diarios3], axis=0, ignore_index=True)\n",
    "df_estacion_datos_diarios=pd.concat([df_estacion_datos_diarios1,df_estacion_datos_diarios3], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estacion_datos_diarios.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtén los descriptores de cada variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## haciendo un dtype vemos que del json a pandas se queda todo como objetos. \n",
    "## Hay que convertir pasar al tipo de dato adecuado para que podamos analizar medias y demas correctamente\n",
    "df_estacion_datos_diarios.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# storing dtype before converting \n",
    "before = df_estacion_datos_diarios.dtypes \n",
    "\n",
    "# converting dtypes\n",
    "     \n",
    "# primero substituyo los comas por puntos a los datos numericos para que pandas no me los convierta a NaN.\n",
    "# para que el replace funciona hay que pasar primero a strings con astype(str)\n",
    "df_estacion_datos_diarios[\"altitud\"]= df_estacion_datos_diarios[\"altitud\"].astype(float)\n",
    "df_estacion_datos_diarios[\"tmed\"]= df_estacion_datos_diarios[\"tmed\"].astype(str).str.replace(\",\", \".\")\n",
    "df_estacion_datos_diarios[\"prec\"]= df_estacion_datos_diarios[\"prec\"].astype(str).str.replace(\",\", \".\")\n",
    "df_estacion_datos_diarios[\"tmin\"]= df_estacion_datos_diarios[\"tmin\"].astype(str).str.replace(\",\", \".\")\n",
    "df_estacion_datos_diarios[\"tmax\"]= df_estacion_datos_diarios[\"tmax\"].astype(str).str.replace(\",\", \".\")\n",
    "df_estacion_datos_diarios[\"dir\"]= df_estacion_datos_diarios[\"dir\"].astype(str).str.replace(\",\", \".\")\n",
    "df_estacion_datos_diarios[\"velmedia\"]= df_estacion_datos_diarios[\"velmedia\"].astype(str).str.replace(\",\", \".\")\n",
    "df_estacion_datos_diarios[\"racha\"]= df_estacion_datos_diarios[\"racha\"].astype(str).str.replace(\",\", \".\")\n",
    "df_estacion_datos_diarios[\"sol\"]= df_estacion_datos_diarios[\"sol\"].astype(str).str.replace(\",\", \".\")\n",
    "df_estacion_datos_diarios[\"presmax\"]= df_estacion_datos_diarios[\"presmax\"].astype(str).str.replace(\",\", \".\")\n",
    "df_estacion_datos_diarios[\"presmin\"]= df_estacion_datos_diarios[\"presmin\"].astype(str).str.replace(\",\", \".\")\n",
    "\n",
    "\n",
    "df_estacion_datos_diarios[\"fecha\"]=pd.to_datetime(df_estacion_datos_diarios[\"fecha\"], format='%Y-%m-%d', errors='coerce')               \n",
    "df_estacion_datos_diarios[\"altitud\"]= pd.to_numeric(df_estacion_datos_diarios[\"altitud\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"tmed\"]=pd.to_numeric(df_estacion_datos_diarios[\"tmed\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"prec\"]=pd.to_numeric(df_estacion_datos_diarios[\"prec\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"tmin\"]=pd.to_numeric(df_estacion_datos_diarios[\"tmin\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"tmax\"]=pd.to_numeric(df_estacion_datos_diarios[\"tmax\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"dir\"]=pd.to_numeric(df_estacion_datos_diarios[\"dir\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"velmedia\"]= pd.to_numeric(df_estacion_datos_diarios[\"velmedia\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"racha\"]=pd.to_numeric(df_estacion_datos_diarios[\"racha\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"sol\"]=pd.to_numeric(df_estacion_datos_diarios[\"sol\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"presmax\"]=pd.to_numeric(df_estacion_datos_diarios[\"presmax\"], errors='coerce')\n",
    "df_estacion_datos_diarios[\"presmin\"]=pd.to_numeric(df_estacion_datos_diarios[\"presmin\"], errors='coerce')\n",
    "\n",
    "# storing dtype after converting \n",
    "after = df_estacion_datos_diarios.dtypes \n",
    "  \n",
    "# printing to compare \n",
    "print(\"BEFORE CONVERSION\\n\", before, \"\\n\") \n",
    "print(\"AFTER CONVERSION\\n\", after, \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estacion_datos_diarios.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pongo las definiciones de los campos FYI\n",
    "  \"campos\": [\n",
    "  \t{\"id\":\"fecha\",\n",
    "\t\"descripcion\": \"fecha del dia (AAAA-MM-DD)\",\n",
    "\t\"tipo_datos\": \"string\",\n",
    "    \t\"requerido\": true\n",
    "    },\n",
    "\t{\"id\":\"indicativo\",\n",
    "\t\"descripcion\": \"indicativo climatológico\",\n",
    "\t\"tipo_datos\": \"string\",\n",
    "    \t\"requerido\": true\n",
    "\t\n",
    "    },\n",
    "\t{\"id\": \"nombre\",\n",
    "\t\"descripcion\": \"nombre (ubicación) de la estación\",\n",
    "\t\"tipo_datos\": \"string\",\n",
    "    \t\"requerido\": true \n",
    "    },\n",
    "\t{\"id\": \"provincia\",\n",
    "\t\"descripcion\": \"provincia de la estación\",\n",
    "\t\"tipo_datos\": \"string\",\n",
    "    \t\"requerido\": true\n",
    "    },\n",
    "\t{\"id\": \"altitud\",\n",
    "\t\"descripcion\": \"altitud de la estación en m sobre el nivel del mar\",\n",
    "\t\"tipo_datos\": \"float\",\n",
    "\t\"unidad\": \"m\",\n",
    "    \t\"requerido\": true\n",
    "    },\n",
    "\t{\"id\":\"tmed\",\n",
    "\t\"descripcion\": \"Temperatura media diaria\",\n",
    "\t\"tipo_datos\": \"float\",\n",
    "\t\"unidad\": \"grados celsius\",\n",
    "    \t\"requerido\": false\n",
    "    },\n",
    "\t{\"id\":\"prec\",\n",
    "        \"descripcion\": \"Precipitación diaria de 07 a 07\",\n",
    "        \"tipo_datos\": \"float\",\n",
    "        \"unidad\": \"mm (Ip = inferior a 0,1 mm)\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"tmin\",\n",
    "        \"descripcion\": \"Temperatura Mínima del día\",\n",
    "        \"tipo_datos\": \"float\",\n",
    "        \"unidad\": \"ºC\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"horatmin\",\n",
    "        \"descripcion\": \"Hora y minuto de la temperatura mínima\",\n",
    "        \"tipo_datos\": \"string\",\n",
    "\t\"unidad\": \"UTC\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"tmax\",\n",
    "        \"descripcion\": \"Temperatura Máxima del día\",\n",
    "        \"tipo_datos\": \"float\",\n",
    "        \"unidad\": \"ºC\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"horatmax\",\n",
    "        \"descripcion\": \"Hora y minuto de la temperatura máxima\",\n",
    "        \"tipo_datos\": \"string\",\n",
    "\t\"unidad\": \"UTC\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"dir\",\n",
    "        \"descripcion\": \"Dirección de la racha máxima\",\n",
    "        \"tipo_datos\": \"float\",\n",
    "        \"unidad\": \"decenas de grado\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"velmedia\",\n",
    "        \"descripcion\": \"Velocidad media del viento\",\n",
    "        \"tipo_datos\": \"float\",\n",
    "        \"unidad\": \"m/s\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"racha\",\n",
    "        \"descripcion\": \"Racha máxima del viento\",\n",
    "        \"tipo_datos\": \"float\",\n",
    "        \"unidad\": \"m/s\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"horaracha\",\n",
    "        \"descripcion\": \"Hora y minuto de la racha máxima\",\n",
    "        \"tipo_datos\": \"string\",\n",
    "\t\"unidad\": \"UTC\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"sol\",\n",
    "        \"descripcion\": \"Insolación\",\n",
    "        \"tipo_datos\": \"float\",\n",
    "\t\"unidad\": \"horas\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"presmax\",\n",
    "        \"descripcion\": \"Presión máxima al nivel de referencia de la estación\",\n",
    "        \"tipo_datos\": \"float\",\n",
    "\t\"unidad\": \"hPa\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"horapresmax\",\n",
    "        \"descripcion\": \"Hora de la presión máxima (redondeada a la hora entera más próxima)\",\n",
    "        \"tipo_datos\": \"string\",\n",
    "\t\"unidad\": \"UTC\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"presmin\",\n",
    "        \"descripcion\": \"Presión mínima al nivel de referencia de la estación\",\n",
    "        \"tipo_datos\": \"float\",\n",
    "\t\"unidad\": \"hPa\",\n",
    "        \"requerido\": false\n",
    "    },\n",
    "        {\"id\":\"horapresmin\",\n",
    "        \"descripcion\": \"Hora de la presión mínima (redondeada a la hora entera más próxima)\",\n",
    "        \"tipo_datos\": \"string\",\n",
    "\t\"unidad\": \"UTC\",\n",
    "        \"requerido\": false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### vemos las medidas del dataset\n",
    "df_estacion_datos_diarios.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Vamos a visualizar las filas problematicas con 'Varias' a ver que hacemos con esto\n",
    "\n",
    "df_estacion_datos_diarios[df_estacion_datos_diarios.eq('Varias').any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estacion_datos_diarios.isin(['Varias']).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parecen ser en campos relacionados con la hora en que se produce un valor minimo o maximo. Seguramente si se dio el caso que hay mas de una hora con una minima o una maxima el data set no se moja y nos dice \"varias\".\n",
    "#### Dejaremos de momento estas filas donde tenemos \"varias\" maximas y minimas y trataremos el problema si consideramos que las horas del dia son relevantes.\n",
    "\n",
    "#### Vemos tambien hay Nulos /NAN. Hacemos lo mismo a ver que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estacion_datos_diarios[df_estacion_datos_diarios.isnull().any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estacion_datos_diarios.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### vamos a rellenar los nulls con las medianas de los mismos dias excepto los campos tipo horamin horamax. \n",
    "##### tendremos valores muy diferentes dependiendo la estacionalidad? (verano = calor / invierno = frio) , precipitaciones?\n",
    "##### para tenerla en cuenta mas facilmente sacaremos los campos year, month,week y season de la fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estacion_datos_diarios['season'] = (df_estacion_datos_diarios['fecha'].dt.month%12 + 3)//3\n",
    "\n",
    "seasons = {\n",
    "             1: 'Winter',\n",
    "             2: 'Spring',\n",
    "             3: 'Summer',\n",
    "             4: 'Autumn'\n",
    "}\n",
    "\n",
    "df_estacion_datos_diarios['season_name'] = df_estacion_datos_diarios['season'].map(seasons)\n",
    "\n",
    "import datetime\n",
    "df_estacion_datos_diarios['year'] = pd.DatetimeIndex(df_estacion_datos_diarios['fecha']).year\n",
    "df_estacion_datos_diarios['month'] = pd.DatetimeIndex(df_estacion_datos_diarios['fecha']).month\n",
    "df_estacion_datos_diarios['week'] = pd.DatetimeIndex(df_estacion_datos_diarios['fecha']).week\n",
    "\n",
    "#transformo month y year a string para sacar el month-year\n",
    "df_estacion_datos_diarios['month']= df_estacion_datos_diarios['month'].astype(str)\n",
    "df_estacion_datos_diarios['year']= df_estacion_datos_diarios['year'].astype(str)\n",
    "df_estacion_datos_diarios['month-year'] = df_estacion_datos_diarios[['month', 'year']].agg('-'.join, axis=1)\n",
    "\n",
    "df_estacion_datos_diarios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prec = df_estacion_datos_diarios['prec'].loc[df_estacion_datos_diarios['prec'] != 'NaN']\n",
    "#precmedian = prec.astype(str).astype(float).median()\n",
    "#df_estacion_datos_diarios['prec'].fillna(precmedian, inplace = True)\n",
    "\n",
    "# al combinar datos de diferentes estaciones muchos campos de algunas estaciones vienen vacios. \n",
    "# supongo que se trata de estaciones menos avanzadas que recogen menos tipos de valores. \n",
    "# rellenaremos los nuls con los valores medianos de la misma fecha aun que vengan de otras estaciones de la ciudad\n",
    "df_estacion_datos_diarios['tmed'] = df_estacion_datos_diarios['tmed'].fillna(df_estacion_datos_diarios.groupby('fecha')['tmed'].transform('median'))\n",
    "df_estacion_datos_diarios['prec'] = df_estacion_datos_diarios['prec'].fillna(df_estacion_datos_diarios.groupby('fecha')['prec'].transform('median'))\n",
    "df_estacion_datos_diarios['tmin'] = df_estacion_datos_diarios['tmin'].fillna(df_estacion_datos_diarios.groupby('fecha')['tmin'].transform('median'))\n",
    "df_estacion_datos_diarios['tmax'] = df_estacion_datos_diarios['tmax'].fillna(df_estacion_datos_diarios.groupby('fecha')['tmax'].transform('median'))\n",
    "df_estacion_datos_diarios['dir'] = df_estacion_datos_diarios['dir'].fillna(df_estacion_datos_diarios.groupby('fecha')['dir'].transform('median'))\n",
    "df_estacion_datos_diarios['velmedia'] = df_estacion_datos_diarios['velmedia'].fillna(df_estacion_datos_diarios.groupby('fecha')['velmedia'].transform('median'))\n",
    "df_estacion_datos_diarios['racha'] = df_estacion_datos_diarios['racha'].fillna(df_estacion_datos_diarios.groupby('fecha')['racha'].transform('median'))\n",
    "df_estacion_datos_diarios['sol'] = df_estacion_datos_diarios['sol'].fillna(df_estacion_datos_diarios.groupby('fecha')['sol'].transform('median'))\n",
    "df_estacion_datos_diarios['presmax'] = df_estacion_datos_diarios['presmax'].fillna(df_estacion_datos_diarios.groupby('fecha')['presmax'].transform('median'))\n",
    "df_estacion_datos_diarios['presmin'] = df_estacion_datos_diarios['presmin'].fillna(df_estacion_datos_diarios.groupby('fecha')['presmin'].transform('median'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_estacion_datos_diarios.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez eliminados los nulls y añadidos los capmos de estacion, año, mes y semana, haciendo un describe vemos por donde se mueve cada valor.\n",
    "df_estacion_datos_diarios.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exportaremos 1 csv con los datos post transformacion excepto los campos \"horas\"\n",
    "df_sinhoras_estacion_datos_diarios=df_estacion_datos_diarios[['fecha','indicativo','nombre','provincia','altitud','tmed','prec','tmin','tmax','dir','velmedia','racha','sol','presmax','presmin','month','week','year','season','season_name']]\n",
    "df_sinhoras_estacion_datos_diarios.to_csv('df_sinhoras_estacion_datos_diarios_bcn_2020.csv', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Increase the size of the heatmap.\n",
    "plt.figure(figsize=(21, 8))\n",
    "# Store heatmap object in a variable to easily access it when you want to include more features (such as title).\n",
    "# Set the range of values to be displayed on the colormap from -1 to 1, and set the annotation to True to display the correlation values on the heatmap.\n",
    "heatmap = sns.heatmap(df_estacion_datos_diarios.corr(), vmin=-1, vmax=1, annot=True)\n",
    "# Give a title to the heatmap. Pad defines the distance of the title from the top of the heatmap.\n",
    "heatmap.set_title('Heatmap de correlaciones', fontdict={'fontsize':20}, pad=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import pairplot\n",
    "##visualizaremos graficos para datos de temperatura,viento,precipitacion,insolacion y presion vs fechas\n",
    "sns.set_style(\"darkgrid\")\n",
    "subframe_estacion_datos_diarios=df_estacion_datos_diarios[['tmed','prec','velmedia','sol','presmax','presmin','month','week','year','season_name','fecha']]\n",
    "sns.pairplot(subframe_estacion_datos_diarios,hue='season_name',palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import lmplot\n",
    "#vamos a ver la evolucion de la temperatura media por fecha\n",
    "plt.figure(figsize=(20, 6))\n",
    "lmplot('fecha', 'tmed',hue='season_name',palette='Set1', data=df_estacion_datos_diarios, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import lmplot\n",
    "#vamos a ver la evolucion de la temperatura media por fecha\n",
    "plt.figure(figsize=(20, 6))\n",
    "lmplot('fecha', 'prec',hue='season_name',palette='Set1', data=df_estacion_datos_diarios, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import lmplot\n",
    "#vamos a ver la evolucion del viento medio por fecha\n",
    "plt.figure(figsize=(20, 6))\n",
    "lmplot('fecha', 'velmedia',hue='season_name',palette='Set1', data=df_estacion_datos_diarios, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import lmplot\n",
    "#vamos a ver la evolucion de la racha de viento por fecha\n",
    "plt.figure(figsize=(20, 6))\n",
    "lmplot('fecha', 'racha',hue='season_name',palette='Set1', data=df_estacion_datos_diarios, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import lmplot\n",
    "#vamos a ver la evolucion de la insolacion por fecha\n",
    "plt.figure(figsize=(20, 6))\n",
    "lmplot('fecha', 'sol',hue='season_name',palette='Set1', data=df_estacion_datos_diarios, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import lmplot\n",
    "#vamos a ver la evolucion de la presion max por fecha\n",
    "plt.figure(figsize=(20, 6))\n",
    "lmplot('fecha', 'presmax',hue='season_name',palette='Set1', data=df_estacion_datos_diarios, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import lmplot\n",
    "#vamos a ver la evolucion de la presion max por fecha\n",
    "plt.figure(figsize=(20, 6))\n",
    "lmplot('fecha', 'presmin',hue='season_name',palette='Set1', data=df_estacion_datos_diarios, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(subframe_estacion_datos_diarios, diag_kind=\"hist\",height=3,hue='season_name',palette='Set1')\n",
    "g.map_lower(sns.kdeplot, levels=3, color=\".7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(subframe_estacion_datos_diarios, hue='season_name',height=4,vars=[\"tmed\", \"prec\",'velmedia','sol','presmax','presmin'],kind='reg',palette='Set1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrama de densidad. temperatura media\n",
    "sns.displot(subframe_estacion_datos_diarios, x=\"tmed\",kind=\"kde\",hue='season_name',palette='Set1',fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrama de caja y bigotes estacion. temperatura media\n",
    "sns.set_theme(style=\"darkgrid\",palette=\"pastel\")\n",
    "sns.boxplot( y=\"tmed\",\n",
    "            x='season_name', palette='Set1',\n",
    "            data=subframe_estacion_datos_diarios)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrama de densidad. precipitaciones\n",
    "sns.displot(subframe_estacion_datos_diarios, x=\"prec\",kind=\"kde\",hue='season_name',palette='Set1',fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrama de caja y bigotes estacion. precipitacion\n",
    "sns.set_theme(style=\"darkgrid\",palette=\"pastel\")\n",
    "sns.boxplot( y=\"prec\",\n",
    "            x='season_name', palette='Set1',\n",
    "            data=subframe_estacion_datos_diarios)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### como tener en cuenta las precipitaciones?. Como normalizarlo? normalmente no llueve por lo que cuando llueve parecen valores atipicos\n",
    "### ver Índice de Precipitación Estandarizado (SPI)\n",
    "http://www.aemet.es/en/serviciosclimaticos/vigilancia_clima/vigilancia_sequia/ayuda\n",
    "https://eliocamp.github.io/codigo-r/2017/12/calcular-ipe-r/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrama de densidad. velocidad del viento\n",
    "sns.displot(subframe_estacion_datos_diarios, x=\"velmedia\",kind=\"kde\",hue='season_name',palette='Set1',fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagrama de caja y bigotes estacion. velocidad viento media\n",
    "sns.set_theme(style=\"darkgrid\",palette=\"pastel\")\n",
    "sns.boxplot( y=\"velmedia\",\n",
    "            x='season_name', palette='Set1',\n",
    "            data=subframe_estacion_datos_diarios)\n",
    "sns.despine(offset=10, trim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_estacion_datos_diarios['velmedia']\n",
    "y=df_estacion_datos_diarios[\"presmax\"]\n",
    "\n",
    "import seaborn as sns  \n",
    "sns.jointplot(x,y,kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_estacion_datos_diarios['velmedia']\n",
    "y=df_estacion_datos_diarios[\"presmin\"]\n",
    "\n",
    "import seaborn as sns  \n",
    "sns.jointplot(x,y,kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_estacion_datos_diarios['racha']\n",
    "y=df_estacion_datos_diarios[\"presmax\"]\n",
    "\n",
    "import seaborn as sns  \n",
    "sns.jointplot(x,y,kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df_estacion_datos_diarios['sol']\n",
    "y=df_estacion_datos_diarios['tmed']\n",
    "\n",
    "import seaborn as sns  \n",
    "sns.jointplot(x,y,kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tiempo.com/noticias/ciencia/altas-presiones-que-contaminan.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import lmplot\n",
    "plt.figure(figsize=(20, 6))\n",
    "lmplot('fecha', \"presmax\",hue='nombre',palette='Set1', data=df_estacion_datos_diarios, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seaborn import lmplot\n",
    "plt.figure(figsize=(20, 6))\n",
    "lmplot('fecha', \"velmedia\",hue='nombre',palette='Set1', data=df_estacion_datos_diarios, fit_reg=False, size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
